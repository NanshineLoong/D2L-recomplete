{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tool import load_data_fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
    "next(iter(train_iter))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    X_sum = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / X_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.normal(0, 1, size=(28 * 28, 10), requires_grad=True)\n",
    "b = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape(-1, w.shape[0]), w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(params, lr, batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    # 预测正确的个数\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()\n",
    "    metrics = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            y_pred = net(X)\n",
    "            acc = accuracy(y_pred, y)\n",
    "            metrics.add(acc, y.numel())\n",
    "    return metrics[0]/metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net, train_iter, loss_func, optimizer):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "        loss = loss_func(y_hat, y)\n",
    "        if isinstance(optimizer, torch.optim.Optimizer):\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            loss.sum().backward()\n",
    "            optimizer([w,b], lr=0.01, batch_size=X.shape[0])\n",
    "        metric.add(loss.sum(), accuracy(y_hat, y), y.numel())\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, net, train_iter, test_iter, loss_func, optimizer):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch(net, train_iter, loss_func, optimizer)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        print(f'epoch {epoch}, train loss: {train_metrics[0]}, train acc: {train_metrics[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = cross_entropy\n",
    "optimizer = SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss: 3.04766295598348, train acc: 0.5101\n",
      "epoch 1, train loss: 2.7442292922973635, train acc: 0.53975\n",
      "epoch 2, train loss: 2.537665101114909, train acc: 0.5617833333333333\n",
      "epoch 3, train loss: 2.385638902537028, train acc: 0.5788333333333333\n",
      "epoch 4, train loss: 2.2678290891011557, train acc: 0.59205\n",
      "epoch 5, train loss: 2.1728394027709963, train acc: 0.6043666666666667\n",
      "epoch 6, train loss: 2.0933712020874022, train acc: 0.6131166666666666\n",
      "epoch 7, train loss: 2.0259221177419025, train acc: 0.6217666666666667\n",
      "epoch 8, train loss: 1.9674454442342122, train acc: 0.6285166666666666\n",
      "epoch 9, train loss: 1.9158699361165366, train acc: 0.6352333333333333\n"
     ]
    }
   ],
   "source": [
    "train(10, net, train_iter, test_iter, loss_func, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
